{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c753145-1a59-480d-abb2-60f2fa3f416f",
   "metadata": {},
   "source": [
    "# Inputs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d71f6f4-5204-4d2d-8790-249b7b7b1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, zarr, nrrd\n",
    "\n",
    "fix_path = \"/GPFS/yuezhifeng_lab_permanent/share/gong_lab/huanglinling/bigstitch/s2/fused/fused.n5/setup0\"\n",
    "mov_path = \"/GPFS/yuezhifeng_lab_permanent/share/gong_lab/huanglinling/bigstitch/r4s2/fused/fused.n5/setup0\"\n",
    "exp_factor = 1  # replace this with the known expansion factor for your sample to use pre-expansion units\n",
    "\n",
    "# load fix data and spacing\n",
    "fix_zarr = zarr.open(store=zarr.N5Store(fix_path), path=\"timepoint0\",  mode='r')\n",
    "fix_spacing = np.array([0.42, 0.23, 0.23])\n",
    "fix_spacing_s1 = fix_spacing * [1, 2, 2]\n",
    "fix_spacing_s3 = fix_spacing * [4, 8, 8]\n",
    "\n",
    "# load mov data and spacing\n",
    "mov_zarr = zarr.open(store=zarr.N5Store(mov_path), path=\"timepoint0\",  mode='r')\n",
    "mov_spacing = np.array([0.42, 0.23, 0.23])\n",
    "mov_spacing_s1 = mov_spacing * [1, 2, 2]\n",
    "mov_spacing_s3 = mov_spacing * [4, 8, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282cb995-1ffa-45ff-8d12-49a3cf6cab81",
   "metadata": {},
   "source": [
    "# Alignment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102718cb-4dee-4a74-9056-6496692caed8",
   "metadata": {},
   "source": [
    "### global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ab7eb9-5e13-4475-a999-7499632e85bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint16 (368, 1108, 1106)\n",
      "uint16 (349, 1105, 1106)\n",
      "computing fixed spots\n",
      "found 276 fixed spots\n",
      "computing moving spots\n",
      "found 68622 moving spots\n",
      "sorting spots\n",
      "extracting contexts\n",
      "computing pairwise correlations\n",
      "found 194 matched spot pairs\n",
      "aligning\n",
      "Degenerate affine produced, returning default\n"
     ]
    }
   ],
   "source": [
    "# alignment functions\n",
    "from bigstream.align import alignment_pipeline\n",
    "from bigstream.transform import apply_transform\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# output_dir\n",
    "output_dir = '/GPFS/yuezhifeng_lab_permanent/share/gong_lab/zhuqj/hll/debug_bigstream/outipynb'\n",
    "\n",
    "# get global alignment channels\n",
    "fix = fix_zarr['s3'][...]\n",
    "mov = mov_zarr['s3'][...]\n",
    "print(fix.dtype, fix.shape)\n",
    "print(mov.dtype, mov.shape)\n",
    "\n",
    "# resample in xy to save room\n",
    "fix_custom = zoom(fix, (1, 0.5, 0.5), order=1)\n",
    "mov_custom = zoom(mov, (1, 0.5, 0.5), order=1)\n",
    "fix_spacing_custom = fix_spacing_s3 * (1, 2, 2)\n",
    "mov_spacing_custom = mov_spacing_s3 * (1, 2, 2)\n",
    "\n",
    "# define alignment steps\n",
    "ransac_kwargs = {\n",
    "    'blob_sizes':[2, 8],\n",
    "    'cc_radius':12,\n",
    "    'match_threshold':0.6,\n",
    "    'nspots':10000,\n",
    "    'fix_spot_detection_kwargs':{\n",
    "        'threshold':0,\n",
    "        'threshold_rel':0.05,\n",
    "    },\n",
    "    'mov_spot_detection_kwargs':{\n",
    "        'threshold':0,\n",
    "        'threshold_rel':0.01,\n",
    "    },\n",
    "}\n",
    "\n",
    "steps = [('ransac', ransac_kwargs,),]\n",
    "\n",
    "# align\n",
    "affine = alignment_pipeline(\n",
    "    fix_custom, mov_custom,\n",
    "    fix_spacing_custom,\n",
    "    mov_spacing_custom,\n",
    "    steps,\n",
    ")\n",
    "\n",
    "# apply affine only\n",
    "affine_aligned = apply_transform(\n",
    "    fix_zarr['s3'], mov_zarr['s3'],\n",
    "    fix_spacing_s3, mov_spacing_s3,\n",
    "    transform_list=[affine,],\n",
    ")\n",
    "\n",
    "# # write results\n",
    "np.savetxt(f'{output_dir}/affine.mat', affine)\n",
    "nrrd.write(f'{output_dir}/affine.nrrd', affine_aligned.transpose(2,1,0), compression_level=2)\n",
    "\n",
    "# load precomputed results\n",
    "# affine = np.loadtxt('{output_dir}/affine.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3a8ce-5693-4b1b-83b4-8ca1169b85fc",
   "metadata": {},
   "source": [
    "### local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25bf63b9-1732-4b54-b8f2-6ba05b6f0fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster dashboard link:  http://10.11.1.1:8787/status\n",
      "Cluster adapting between 90 and 90 workers with 12 cores per worker\n",
      "*** This cluster has an upper bound cost of 75.6 dollars per hour ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:29:09,116 - distributed.deploy.adaptive_core - INFO - Adaptive stop\n"
     ]
    }
   ],
   "source": [
    "from bigstream.piecewise_align import distributed_piecewise_alignment_pipeline\n",
    "from bigstream.transform import apply_transform\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "output_dir = '/GPFS/yuezhifeng_lab_permanent/share/gong_lab/zhuqj/hll/debug_bigstream/outipynb'\n",
    "\n",
    "# load affine\n",
    "affine_result_path = f'{output_dir}/affine.mat'\n",
    "affine = np.loadtxt(affine_result_path)\n",
    "\n",
    "# get global alignment channels\n",
    "fix = fix_zarr['s3'][...]\n",
    "mov = mov_zarr['s3'][...]\n",
    "\n",
    "# resample in xy to save room\n",
    "fix_custom = zoom(fix, (1, 0.5, 0.5), order=1)\n",
    "mov_custom = zoom(mov, (1, 0.5, 0.5), order=1)\n",
    "fix_spacing_custom = fix_spacing_s3 * (1, 2, 2)\n",
    "mov_spacing_custom = mov_spacing_s3 * (1, 2, 2)\n",
    "\n",
    "# define alignment steps\n",
    "ransac_kwargs = {\n",
    "    'blob_sizes':[2, 8],\n",
    "    'cc_radius':12,\n",
    "    'match_threshold':0.6,\n",
    "    'nspots':10000,\n",
    "    'fix_spot_detection_kwargs':{\n",
    "        'threshold':0,\n",
    "        'threshold_rel':0.05,\n",
    "    },\n",
    "    'mov_spot_detection_kwargs':{\n",
    "        'threshold':0,\n",
    "        'threshold_rel':0.01,\n",
    "    },\n",
    "}\n",
    "\n",
    "affine_kwargs = {\n",
    "    'shrink_factors':(1,),\n",
    "    'smooth_sigmas':(1.,),\n",
    "    'optimizer_args':{\n",
    "        'learningRate':0.25,\n",
    "        'minStep':0.,\n",
    "        'numberOfIterations':400,\n",
    "    },\n",
    "}\n",
    "\n",
    "deform_kwargs = {\n",
    "    'shrink_factors':(2,),\n",
    "    'smooth_sigmas':(2.,),\n",
    "    'control_point_spacing':200.0,\n",
    "    'control_point_levels':(1,),\n",
    "    'optimizer_args':{\n",
    "        'learningRate':2.5,\n",
    "        'minStep':0.07,\n",
    "        'numberOfIterations':100,\n",
    "    },\n",
    "}\n",
    "\n",
    "steps = [('ransac', ransac_kwargs,),\n",
    "         ('affine', affine_kwargs,),\n",
    "         ('deform', deform_kwargs,),]\n",
    "\n",
    "blocksize = [152, 128, 128]\n",
    "\n",
    "# cluster params\n",
    "cluster_kwargs = {\n",
    "    'queue':'q_cn,q_fat,q_fat_l,q_fat_c,q_fat_z',\n",
    "    'job_cpu':12,   # 每个worker的cpu数量\n",
    "    'memory':'30GB', # 每个worker的内存\n",
    "    'threads':1,   \n",
    "    'min_workers':90,   \n",
    "    'max_workers':90,   \n",
    "}\n",
    "\n",
    "# align\n",
    "deform = distributed_piecewise_alignment_pipeline(\n",
    "    fix_custom, mov_custom,\n",
    "    fix_spacing_custom,\n",
    "    mov_spacing_custom,\n",
    "    steps,\n",
    "    blocksize,\n",
    "    static_transform_list=[affine,],\n",
    "    cluster_kwargs=cluster_kwargs,\n",
    ")\n",
    "\n",
    "# apply affine only\n",
    "deform_aligned = apply_transform(\n",
    "    fix_zarr['s3'], mov_zarr['s3'],\n",
    "    fix_spacing_s3, mov_spacing_s3,\n",
    "    transform_list=[affine, deform],\n",
    "    transform_spacing=fix_spacing_custom,\n",
    ")\n",
    "\n",
    "# write results\n",
    "nrrd.write(f'{output_dir}/deform.nrrd', deform, compression_level=2)\n",
    "nrrd.write(f'{output_dir}/deformed.nrrd', deform_aligned.transpose(2,1,0), compression_level=2)\n",
    "\n",
    "# load precomputed results\n",
    "# deform, _ = nrrd.read(f'{output_dir}/deform.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b7b52-f4bf-4ed5-bca2-239825252fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
